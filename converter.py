"""
PT to RKNN Model Converter
åŸºäºæˆåŠŸè½¬æ¢è„šæœ¬çš„æ ¸å¿ƒè½¬æ¢é€»è¾‘
"""
import os
import sys
import torch
from rknn.api import RKNN


class PT2RKNNConverter:
    """PTæ¨¡å‹åˆ°RKNNæ¨¡å‹çš„è½¬æ¢å™¨ï¼ˆæ”¯æŒè‡ªåŠ¨è½¬æ¢TorchScriptï¼‰"""
    
    def __init__(self, verbose=True):
        self.verbose = verbose
        self.rknn = None
    
    def pt_to_torchscript(self, pt_model_path, output_path=None, input_size=(640, 640)):
        """
        å°†æ™®é€šPTæ¨¡å‹è½¬æ¢ä¸ºTorchScriptæ ¼å¼
        
        Args:
            pt_model_path: PTæ¨¡å‹æ–‡ä»¶è·¯å¾„
            output_path: è¾“å‡ºTorchScriptæ–‡ä»¶è·¯å¾„
            input_size: è¾“å…¥å°ºå¯¸ (height, width)
            
        Returns:
            (success, message, torchscript_path)
        """
        try:
            self._log(f"æ£€æµ‹åˆ°æ™®é€šPTæ¨¡å‹ï¼Œæ­£åœ¨è½¬æ¢ä¸ºTorchScript...")
            
            # è®¾ç½®è¾“å‡ºè·¯å¾„
            if not output_path:
                base_name = os.path.splitext(pt_model_path)[0]
                output_path = f"{base_name}_rknnopt.torchscript"
            
            # åŠ è½½PTæ¨¡å‹
            self._log(f"åŠ è½½æ¨¡å‹: {pt_model_path}")
            is_ultralytics = False
            try:
                # å°è¯•ä½¿ç”¨ultralytics
                from ultralytics import YOLO
                model = YOLO(pt_model_path)
                model_obj = model.model
                is_ultralytics = True
                self._log("âœ“ ä½¿ç”¨ultralyticsåŠ è½½æ¨¡å‹æˆåŠŸ")
            except Exception as e1:
                self._log(f"ultralyticsåŠ è½½å¤±è´¥ï¼Œå°è¯•ç›´æ¥åŠ è½½: {e1}")
                try:
                    # å°è¯•ç›´æ¥ç”¨torchåŠ è½½
                    checkpoint = torch.load(pt_model_path, map_location='cpu')
                    if isinstance(checkpoint, dict) and 'model' in checkpoint:
                        model_obj = checkpoint['model']
                        if hasattr(model_obj, 'float'):
                            model_obj = model_obj.float()
                    else:
                        model_obj = checkpoint
                    self._log("âœ“ ä½¿ç”¨torchç›´æ¥åŠ è½½æˆåŠŸ")
                except Exception as e2:
                    return False, f"æ— æ³•åŠ è½½æ¨¡å‹ã€‚ultralyticsé”™è¯¯: {e1}, torché”™è¯¯: {e2}", None
            
            # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
            model_obj.eval()
            
            # å¯¹äºultralyticsæ¨¡å‹ï¼Œè®¾ç½®ä¸ºå¯¼å‡ºæ¨¡å¼
            if is_ultralytics:
                self._log("è®¾ç½®ultralyticsæ¨¡å‹ä¸ºå¯¼å‡ºæ¨¡å¼...")
                # ç¦ç”¨åŠ¨æ€æ“ä½œï¼Œä½¿æ¨¡å‹æ›´å®¹æ˜“trace
                for m in model_obj.modules():
                    # è®¾ç½®Detectå±‚çš„å¯¼å‡ºæ¨¡å¼
                    if hasattr(m, 'export'):
                        m.export = True
                        # å¿…é¡»åŒæ—¶è®¾ç½®formatå±æ€§
                        if not hasattr(m, 'format'):
                            m.format = 'torchscript'
                        self._log(f"  - è®¾ç½® {m.__class__.__name__}.export = True, format = torchscript")
                    # ç¦ç”¨åŠ¨æ€anchorç”Ÿæˆ
                    if hasattr(m, 'dynamic'):
                        m.dynamic = False
                        self._log(f"  - è®¾ç½® {m.__class__.__name__}.dynamic = False")
                    # è®¾ç½®ä¸ºæ¨ç†æ¨¡å¼
                    if hasattr(m, 'inplace'):
                        m.inplace = False
                        self._log(f"  - è®¾ç½® {m.__class__.__name__}.inplace = False")
            
            # åˆ›å»ºç¤ºä¾‹è¾“å…¥
            self._log(f"åˆ›å»ºç¤ºä¾‹è¾“å…¥: [1, 3, {input_size[0]}, {input_size[1]}]")
            dummy_input = torch.randn(1, 3, input_size[0], input_size[1])
            
            # å…ˆæ‰§è¡Œä¸€æ¬¡å‰å‘ä¼ æ’­ï¼Œç¡®ä¿æ‰€æœ‰åŠ¨æ€å±‚åˆå§‹åŒ–
            self._log("é¢„çƒ­æ¨¡å‹ï¼ˆåˆå§‹åŒ–åŠ¨æ€å±‚ï¼‰...")
            with torch.no_grad():
                _ = model_obj(dummy_input)
            
            # è½¬æ¢ä¸ºTorchScript (ç¦ç”¨sanity checkä»¥é¿å…åŠ¨æ€æ“ä½œé—®é¢˜)
            self._log("ä½¿ç”¨torch.jit.traceè½¬æ¢ï¼ˆç¦ç”¨sanity checkï¼‰...")
            with torch.no_grad():
                traced_model = torch.jit.trace(model_obj, dummy_input, strict=False, check_trace=False)
            
            # ä¿å­˜
            self._log(f"ä¿å­˜TorchScriptæ¨¡å‹: {output_path}")
            torch.jit.save(traced_model, output_path)
            
            # éªŒè¯
            if os.path.exists(output_path):
                file_size = os.path.getsize(output_path) / 1024 / 1024
                self._log(f"âœ“ TorchScriptè½¬æ¢æˆåŠŸ! æ–‡ä»¶å¤§å°: {file_size:.2f} MB")
                return True, f"TorchScriptè½¬æ¢æˆåŠŸ", output_path
            else:
                return False, "TorchScriptæ–‡ä»¶æœªç”Ÿæˆ", None
                
        except Exception as e:
            import traceback
            error_detail = traceback.format_exc()
            self._log(f"è½¬æ¢é”™è¯¯è¯¦æƒ…:\n{error_detail}")
            return False, f"PTè½¬TorchScriptå¤±è´¥: {str(e)}", None
    
    def check_model_format(self, model_path):
        """
        æ£€æŸ¥æ¨¡å‹æ ¼å¼æ˜¯å¦ä¸ºTorchScript
        
        Returns:
            (is_torchscript, message)
        """
        try:
            # å°è¯•ä½œä¸ºTorchScriptåŠ è½½
            model = torch.jit.load(model_path)
            return True, "æ¨¡å‹æ ¼å¼æ­£ç¡®ï¼ˆTorchScriptï¼‰"
        except Exception as e:
            error_msg = str(e)
            if "constants.pkl" in error_msg or "PytorchStreamReader" in error_msg:
                return False, "æ¨¡å‹æ˜¯æ™®é€šPTæ ¼å¼ï¼Œéœ€è¦å…ˆè½¬æ¢ä¸ºTorchScript"
            else:
                return False, f"æ¨¡å‹æ ¼å¼æ£€æŸ¥å¤±è´¥: {error_msg}"
        
    def convert(self, 
                pt_model_path,
                platform='rk3576',
                do_quant=True,
                dataset_path=None,
                output_path=None,
                input_size=(640, 640),
                mean_values=[[0, 0, 0]],
                std_values=[[255, 255, 255]],
                optimization_level=3,
                auto_convert_torchscript=True):
        """
        æ‰§è¡ŒPTåˆ°RKNNçš„è½¬æ¢ï¼ˆæ”¯æŒè‡ªåŠ¨è½¬æ¢TorchScriptï¼‰
        
        Args:
            pt_model_path: PTæ¨¡å‹æ–‡ä»¶è·¯å¾„
            platform: ç›®æ ‡å¹³å° (rk3562/rk3566/rk3568/rk3576/rk3588)
            do_quant: æ˜¯å¦é‡åŒ– (True=int8, False=fp)
            dataset_path: æ ¡å‡†æ•°æ®é›†è·¯å¾„ï¼ˆé‡åŒ–æ—¶å¿…éœ€ï¼‰
            output_path: è¾“å‡ºRKNNæ–‡ä»¶è·¯å¾„
            input_size: è¾“å…¥å°ºå¯¸ (height, width)
            mean_values: å‡å€¼
            std_values: æ ‡å‡†å·®
            optimization_level: ä¼˜åŒ–ç­‰çº§ (0-3)
            auto_convert_torchscript: æ˜¯å¦è‡ªåŠ¨è½¬æ¢ä¸ºTorchScript (é»˜è®¤True)
            
        Returns:
            (success, message, output_file)
        """
        torchscript_path = None  # ç”¨äºæ¸…ç†ä¸´æ—¶æ–‡ä»¶
        
        try:
            # å‚æ•°éªŒè¯
            if not os.path.exists(pt_model_path):
                return False, f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {pt_model_path}", None
                
            if platform not in ['rk3562', 'rk3566', 'rk3568', 'rk3576', 'rk3588']:
                return False, f"ä¸æ”¯æŒçš„å¹³å°: {platform}", None
            
            # æ£€æŸ¥æ¨¡å‹æ ¼å¼
            is_torchscript, format_msg = self.check_model_format(pt_model_path)
            
            # å¦‚æœä¸æ˜¯TorchScriptä¸”å…è®¸è‡ªåŠ¨è½¬æ¢
            if not is_torchscript and auto_convert_torchscript:
                self._log(f"âš ï¸  {format_msg}")
                self._log("ğŸ”„ è‡ªåŠ¨è½¬æ¢æ¨¡å¼å·²å¯ç”¨ï¼Œå¼€å§‹è½¬æ¢...")
                
                # è½¬æ¢ä¸ºTorchScript
                success, msg, torchscript_path = self.pt_to_torchscript(
                    pt_model_path, 
                    input_size=input_size
                )
                
                if not success:
                    return False, f"TorchScriptè½¬æ¢å¤±è´¥: {msg}", None
                
                # ä½¿ç”¨è½¬æ¢åçš„TorchScriptæ–‡ä»¶
                pt_model_path = torchscript_path
                self._log(f"âœ“ å°†ä½¿ç”¨è½¬æ¢åçš„æ¨¡å‹: {torchscript_path}")
                
            elif not is_torchscript:
                # ä¸å…è®¸è‡ªåŠ¨è½¬æ¢ï¼Œè¿”å›é”™è¯¯
                error_msg = f"{format_msg}\n\n"
                error_msg += "âŒ é”™è¯¯ï¼šRKNNéœ€è¦TorchScriptæ ¼å¼çš„æ¨¡å‹\n\n"
                error_msg += "ğŸ“ è§£å†³æ–¹æ³•ï¼š\n"
                error_msg += "1. å¯ç”¨è‡ªåŠ¨è½¬æ¢ï¼ˆæ¨èï¼‰\n"
                error_msg += "2. æ‰‹åŠ¨å¯¼å‡ºTorchScriptï¼š\n"
                error_msg += "   from ultralytics import YOLO\n"
                error_msg += "   model = YOLO('your_model.pt')\n"
                error_msg += "   model.export(format='torchscript')"
                return False, error_msg, None
            else:
                self._log(f"âœ“ {format_msg}")
            
            # é‡åŒ–éœ€è¦æ•°æ®é›†
            if do_quant and not dataset_path:
                return False, "é‡åŒ–æ¨¡å¼éœ€è¦æä¾›æ ¡å‡†æ•°æ®é›†", None
                
            if do_quant and dataset_path and not os.path.exists(dataset_path):
                return False, f"æ ¡å‡†æ•°æ®é›†æ–‡ä»¶ä¸å­˜åœ¨: {dataset_path}", None
            
            # è®¾ç½®è¾“å‡ºè·¯å¾„
            if not output_path:
                model_name = os.path.splitext(os.path.basename(pt_model_path))[0]
                # ç§»é™¤å¯èƒ½çš„_rknnoptåç¼€
                model_name = model_name.replace('_rknnopt', '')
                quant_suffix = 'i8' if do_quant else 'fp'
                output_path = f"./output/{model_name}_{platform}_{quant_suffix}.rknn"
            
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            output_dir = os.path.dirname(output_path)
            if output_dir and not os.path.exists(output_dir):
                os.makedirs(output_dir, exist_ok=True)
            
            # åˆå§‹åŒ–RKNN
            self._log("åˆå§‹åŒ–RKNN...")
            self.rknn = RKNN(verbose=self.verbose)
            
            # é…ç½®æ¨¡å‹
            self._log("é…ç½®æ¨¡å‹å‚æ•°...")
            self.rknn.config(
                mean_values=mean_values,
                std_values=std_values,
                target_platform=platform,
                quantized_algorithm='normal',
                quantized_method='channel',
                optimization_level=optimization_level
            )
            
            # åŠ è½½æ¨¡å‹
            self._log(f"åŠ è½½TorchScriptæ¨¡å‹åˆ°RKNN: {pt_model_path}")
            ret = self.rknn.load_pytorch(
                model=pt_model_path,
                input_size_list=[[1, 3, input_size[0], input_size[1]]]
            )
            if ret != 0:
                return False, "RKNNåŠ è½½æ¨¡å‹å¤±è´¥", None
            
            # æ„å»ºæ¨¡å‹
            self._log(f"æ„å»ºRKNNæ¨¡å‹ (é‡åŒ–: {'æ˜¯' if do_quant else 'å¦'})...")
            ret = self.rknn.build(
                do_quantization=do_quant,
                dataset=dataset_path if do_quant else None,
                rknn_batch_size=1
            )
            if ret != 0:
                return False, "RKNNæ„å»ºæ¨¡å‹å¤±è´¥", None
            
            # å¯¼å‡ºæ¨¡å‹
            self._log(f"å¯¼å‡ºRKNNæ¨¡å‹: {output_path}")
            ret = self.rknn.export_rknn(output_path)
            if ret != 0:
                return False, "RKNNå¯¼å‡ºæ¨¡å‹å¤±è´¥", None
            
            # éªŒè¯è¾“å‡ºæ–‡ä»¶
            if os.path.exists(output_path):
                file_size = os.path.getsize(output_path) / 1024 / 1024
                self._log(f"âœ“ è½¬æ¢æˆåŠŸ! æ–‡ä»¶å¤§å°: {file_size:.2f} MB")
                return True, f"è½¬æ¢æˆåŠŸï¼Œæ–‡ä»¶å¤§å°: {file_size:.2f} MB", output_path
            else:
                return False, "è¾“å‡ºæ–‡ä»¶æœªç”Ÿæˆ", None
                
        except Exception as e:
            import traceback
            error_detail = traceback.format_exc()
            self._log(f"è½¬æ¢é”™è¯¯:\n{error_detail}")
            return False, f"è½¬æ¢è¿‡ç¨‹å‡ºé”™: {str(e)}", None
            
        finally:
            # æ¸…ç†èµ„æº
            if self.rknn:
                self.rknn.release()
                self.rknn = None
            
            # æ¸…ç†ä¸´æ—¶TorchScriptæ–‡ä»¶ï¼ˆå¯é€‰ï¼‰
            # if torchscript_path and os.path.exists(torchscript_path):
            #     try:
            #         os.remove(torchscript_path)
            #         self._log(f"âœ“ æ¸…ç†ä¸´æ—¶æ–‡ä»¶: {torchscript_path}")
            #     except:
            #         pass
    
    def _log(self, message):
        """æ—¥å¿—è¾“å‡º"""
        if self.verbose:
            print(f"[Converter] {message}")


def main():
    """å‘½ä»¤è¡Œå…¥å£"""
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python converter.py <pt_model_path> [platform] [quant_type] [output_path]")
        print("  platform: rk3562/rk3566/rk3568/rk3576/rk3588 (é»˜è®¤: rk3576)")
        print("  quant_type: i8/fp (é»˜è®¤: i8)")
        print("  output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„ (å¯é€‰)")
        print("\nç¤ºä¾‹: python converter.py model.pt rk3576 i8")
        sys.exit(1)
    
    pt_model = sys.argv[1]
    platform = sys.argv[2] if len(sys.argv) > 2 else 'rk3576'
    quant_type = sys.argv[3] if len(sys.argv) > 3 else 'i8'
    output_path = sys.argv[4] if len(sys.argv) > 4 else None
    
    do_quant = (quant_type == 'i8')
    dataset_path = './calibration_data/calibration.txt' if do_quant else None
    
    converter = PT2RKNNConverter(verbose=True)
    success, message, output_file = converter.convert(
        pt_model_path=pt_model,
        platform=platform,
        do_quant=do_quant,
        dataset_path=dataset_path,
        output_path=output_path
    )
    
    if success:
        print(f"\nâœ“ æˆåŠŸ: {message}")
        print(f"âœ“ è¾“å‡ºæ–‡ä»¶: {output_file}")
        sys.exit(0)
    else:
        print(f"\nâœ— å¤±è´¥: {message}")
        sys.exit(1)


if __name__ == '__main__':
    main()
